---
title: "Predicting Rocket League Game Outcome Through Statistical Modeling"
author:
  - name: "By Tanner Bessette"
  - name: "Faculty Advisor: Professor Matthew Higham"
affiliation: 
  - address: "Department of Mathematics, Computer Science & Statistics"
  - address: "St. Lawrence University"
column_numbers: 3
logoright_name: https&#58;//raw.githubusercontent.com/TannerBessette/SLU_Fellows/main/Images/Rocket_League_Logo.png
logoleft_name: https&#58;//raw.githubusercontent.com/TannerBessette/SLU_Fellows/main/Images/St_Lawrence_Logo.png
output: 
  posterdown::posterdown_html:
    sections:
      - name: "What is Rocket League?"
        colspan: 1
      - name: "Project Goals"
        colspan: 1
        start: 2
      - name: "Methods"
        colspan: 1
      - name: "What is Random Forest?"
        colspan: 1
      - name: "Decision Tree Example"
        colspan: 1
        start: 2
      - name: "Results"
        colspan: 1
      - name: "Conclusion"
        colspan: 1
    self_contained: false
bibliography: packages.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# What is Rocket League?

-   One of the most popular video games/esports in the world

-   5 minute soccer games played in cars

-   Every player controls a rocket powered car

-   Multiple game modes - but only 3v3 mode explored for this project

# Project Goals

-   Train a model on professional Rocket League games and use that model to predict match outcomes (win/loss) for other professional Rocket League games

-   Get an idea of which variables are most associated with winning games

-   Potentially use these findings to understand whether certain tactics/strategies used by professional teams are more or less effective

# Dataset and Variables

-   Data spans multiple Rocket League Championship Series tournaments throughout 2021-2022

-   Team difference variables were created for each game by calculating blue team's stats - orange team's stats

-   Investigating different play styles involved:

    -   Calculating standard deviations per team per game for all variables

    -   Calculating standard deviation differences (blue team - orange team)

-   Example of row of data and some variables in the dataset:

    ```{r echo = FALSE, message = FALSE, out.width = "100%", out.height = "200%"}
    library(tidyverse)
    library(here)
    RL_numeric <- read_csv(here("RL_Datasets/RL_numeric.csv"), 
            col_types = cols(winner_factor = readr::col_factor()))
    # choose certain example variables to show
    RL_example_row <- RL_numeric %>%
                    select(winner_factor,
                        movement_time_supersonic_speed_diff,
                        positioning_time_defensive_half_diff,
                        core_shots_diff,
                        sd_core_shots_blue_diff,
                        boost_avg_amount_diff) 

    # rename sd_core_shots_blue_diff
    RL_example_row <- RL_example_row %>% 
      rename(sd_shots_diff = sd_core_shots_blue_diff,
             winner = winner_factor,
             supersonic_diff = movement_time_supersonic_speed_diff)

    # select only three variables to show from dataset:
    RL_example_row <- RL_example_row |>
      select(winner, supersonic_diff, sd_shots_diff)

    # pick a row from the dataset
    RL_example_row <- RL_example_row[2, ]

    # output an image of this row of data:

    RL_example_row
    # image of it: knitr::include_graphics(here("Images/Dataset_row.png"))
    ```

# Methods

-   Built a random forest statistical model

    -   Utilized classification approach to predict win/loss

-   Incorporated cross validation in the model - a resampling method that creates different splits of training and test data to evaluate model performance

# What is Random Forest?

```{r echo = FALSE, message = FALSE, out.width = "100%"}
library(here)
knitr::include_graphics(here("Images/Canva_RF.png"))
## source: https://www.analyticsvidhya.com/blog/2022/07/data-science-interview-series-part-2-random-forest-and-svm/'
```

-   After cross-validation, bootstrapping occurs; the set-aside training data is sampled with replacement to create many different simulated samples

-   Next, a random subset of variables from the full dataset are used to create a decision tree that is fit to each bootstrapped sample

-   Each decision tree runs independently, and makes a classification prediction (predicted win or loss)

-   Whichever result was predicted by the highest number of decision trees is the model's final prediction

-   Here's an example of a single decision tree:

    ```{r morefigs, out.width='90%', echo=FALSE, message = FALSE, fig.height = 4}
    #fig.cap='Amazing, right?!'
    library(tidyverse)
    library(tidymodels)
    library(tree)
    library(ggplot2)
    library(rpart)
    library(rpart.plot)
    library(knitr)
    library(here)
    library(vip)
    library(caret)
    # create a dataset with a subset of variables to make an example tree
    RL_numeric_tree_example <- RL_numeric |> 
                      select(c("winner_factor", 
                               "movement_time_high_air_diff",
                               "boost_time_zero_boost_diff",
                               "movement_time_slow_speed_diff",
                               "positioning_time_defensive_third_diff",
                               "positioning_time_offensive_half_diff"))

    # fct_relevel to start factor variable at 0 instead of 1
    RL_numeric_tree_example <- RL_numeric_tree_example |> 
      mutate(winner_factor = fct_relevel(winner_factor, "0"))

    # plot the example decision tree
    clean_tree <- rpart(winner_factor ~ ., 
                        data = RL_numeric_tree_example)
    rpart.plot(clean_tree)
    ```

# Decision Tree Example

-   Let's observe a Rocket League game where boost time zero boost diff = -1 and positioning time offensive half diff = 15

-   Start by observing boost time zero boost diff; -1 is less than 0.8, so it goes down to the right bubble in the bottom row

-   At the top of that bubble is the number 1, which indicates a predicted win for blue team

# Results

```{r out.width='80%', echo=FALSE, message = FALSE, fig.height = 4}

# set a seed
set.seed(12)
RL_splits <- group_initial_split(RL_numeric, group = series_id, prop = 0.5)
RL_train <- training(RL_splits)
RL_test <- testing(RL_splits)
RL_resamples <- group_vfold_cv(RL_train, v = 5, group = series_id)


# Preprocess the data for modelling
RL_recipe <- recipe(winner_factor ~ ., data = RL_train) %>% 
  step_rm(series_id) %>%
  step_normalize(all_numeric_predictors()) 

# Build a random forest model specification
rf_spec <- rand_forest() %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("classification")

# Bundle recipe and model spec into a workflow
rf_wf <- workflow() %>% 
  add_recipe(RL_recipe) %>% 
  add_model(rf_spec)

# Fit a model
rf_wf_fit <- rf_wf %>% 
  fit(data = RL_train)

# Extract the fitted model from the workflow
vip_plot <- rf_wf_fit %>% 
  extract_fit_parsnip() 

# Make VIP plot
vip_plot <- vip(vip_plot, num_features = 4) +
  labs(color = "marital")

# plot 
print(vip_plot)

# potentially add back to conclusion: , and players may already have all of their roles set within each team
```

-   Two clear strongest predictor variables: difference in positioning time behind the ball and difference in shots

-   None of the car speed predictors proved to be strong predictors

-   No standard deviation differences proved to be strong predictors

-   Final model predicted game outcome with **86.35% accuracy**

# Conclusion

-   Results reinforce the idea that keeping constant pressure on your opponent is the most effective Rocket League strategy

-   Keeping speed high throughout games may be effective in *reaching* the highest level, but once at the professional level it does not appear to be a significant indicator of game outcome

-   No significant standard deviation difference predictors means that we cannot definitively determine whether certain team tactics are more associated with winning games

    -   At the highest level of Rocket League, there may not be significant differences in tactical approaches among teams

    -   With further exploration, certain strategic approaches may still prove to be more effective
