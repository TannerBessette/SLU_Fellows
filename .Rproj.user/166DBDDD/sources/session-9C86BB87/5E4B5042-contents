---
title: "Lasso Practice Using Tidymodels"
format: html
---

Load any potential libraries:
```{r}
library(tidyverse)
library(tidymodels)
library(broom)
library(gt)
library(patchwork)
library(tictoc)
library(ISLR2)
library(ggplot2)
library(dplyr)
library(glmnet)
```

Use the dataset for the lasso model:
```{r}
library(ISLR2)
data(Auto)
head(Auto)
```

Select only numeric variables from Auto dataset to use as predictors:
```{r}
Auto_numeric <- Auto %>% select_if(is.numeric)
Auto_numeric <- Auto_numeric %>% select_if(~ sd(.) > 0)
sum(is.na(Auto_numeric))
```

```{r}
view(Auto)
```


```{r}
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

Auto_recipe <- 
  recipe(mpg ~ ., data = Auto_numeric) %>%
  step_normalize(all_predictors())

Auto_workflow <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(Auto_recipe)
```

```{r}
set.seed(5)
Auto_resamples <- vfold_cv(Auto_numeric, v = 10)

Auto_tune_res <-
  tune_grid(Auto_workflow, resamples = Auto_resamples,
            grid = grid_regular(penalty(range = c(-5, 1)), levels = 50))
autoplot(Auto_tune_res)
```

```{r}
Auto_workflow_final <-
  finalize_workflow(Auto_workflow, select_best(Auto_tune_res, metric = "rsq"))
fit(Auto_workflow_final, data = Auto) %>%
  tidy() %>%
  filter(estimate != 0)
```

Using rmse, for some reason variable selection was not performed and the model
included all of te variables with an extremely low penalty (0.0001). Using a 
different metric, rsq, it chose the best subset of 4 predictors and had a more
reasonable penalty value of 0.256 for all of the variables. 













Fitting a Lasso model to RL dataset:
```{r}
RL_numeric <- read_csv("~/Desktop/RL_numeric.csv")
```

```{r}
RL_numeric <- RL_numeric |> select(-c("core_assists_diff",
                                      "core_score_diff"))
```

Split the data into train/test split:
```{r}
set.seed(993)
RL_splits <- initial_split(RL_numeric, prop = 0.5)
RL_train <- training(RL_splits)
RL_test <- testing(RL_splits)
```

```{r}
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet", family = "binomial")

RL_recipe <- 
  recipe(winner_numeric ~ ., 
         data = RL_train) %>%
  step_normalize(all_predictors())

RL_workflow <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(RL_recipe)
```

```{r}
set.seed(5)
RL_resamples <- vfold_cv(RL_numeric, v = 10)

RL_tune_res <-
  tune_grid(RL_workflow, resamples = RL_resamples,
            grid = grid_regular(penalty(range = c(-1, 0)), levels = 50))
autoplot(RL_tune_res)
```

```{r}
RL_workflow_final <-
  finalize_workflow(RL_workflow, select_best(RL_tune_res, metric = "rmse"))
RL_fit <- fit(RL_workflow_final, data = RL_train)
results <- fit(RL_workflow_final, data = RL_numeric) %>%
  tidy() %>%
  filter(estimate != 0)
print(results, n = 42)
```


Evaluate model:
```{r}
Lasso_predictions <- predict(RL_fit, new_data = RL_test)
Lasso_predictions <- if_else(Lasso_predictions > 0.5, 
                       true = TRUE, 
                       false = FALSE)
accuracy <- mean(Lasso_predictions == RL_test$winner_numeric)
accuracy
```

The Lasso model classified game outcome with 73.03% accuracy.


