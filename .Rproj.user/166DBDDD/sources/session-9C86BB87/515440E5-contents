---
title: "Lasso Practice Using Tidymodels"
format: html
---

Load any potential libraries:
```{r}
library(tidyverse)
library(tidymodels)
library(broom)
library(gt)
library(patchwork)
library(tictoc)
library(ISLR2)
library(ggplot2)
library(dplyr)
library(glmnet)
```

Use the dataset for the lasso model:
```{r}
library(ISLR2)
data(Auto)
head(Auto)
```

Select only numeric variables from Auto dataset to use as predictors:
```{r}
Auto_numeric <- Auto %>% select_if(is.numeric)
Auto_numeric <- Auto_numeric %>% select_if(~ sd(.) > 0)
sum(is.na(Auto_numeric))
```

```{r}
view(Auto)
```


```{r}
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

Auto_recipe <- 
  recipe(mpg ~ ., data = Auto_numeric) %>%
  step_normalize(all_predictors())

Auto_workflow <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(Auto_recipe)
```

```{r}
set.seed(5)
Auto_resamples <- vfold_cv(Auto_numeric, v = 10)

Auto_tune_res <-
  tune_grid(Auto_workflow, resamples = Auto_resamples,
            grid = grid_regular(penalty(range = c(-5, 1)), levels = 50))
autoplot(Auto_tune_res)
```

```{r}
Auto_workflow_final <-
  finalize_workflow(Auto_workflow, select_best(Auto_tune_res, metric = "rsq"))
fit(Auto_workflow_final, data = Auto) %>%
  tidy() %>%
  filter(estimate != 0)
```

Using rmse, for some reason variable selection was not performed and the model
included all of te variables with an extremely low penalty (0.0001). Using a 
different metric, rsq, it chose the best subset of 4 predictors and had a more
reasonable penalty value of 0.256 for all of the variables. 













Fitting a Lasso model to RL dataset:
```{r}
view(team_diff)
```

```{r}
RL_numeric <- team_diff %>% select_if(is.numeric)
RL_numeric <- na.omit(RL_numeric)
sum(is.na(RL_numeric))
```

```{r}
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

RL_recipe <- 
  recipe(winner_binary ~ core_saves_diff + core_assists_diff, 
         data = RL_numeric) %>%
  step_normalize(all_predictors())

RL_workflow <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(RL_recipe)
```

```{r}
set.seed(5)
RL_resamples <- vfold_cv(RL_numeric, v = 10)

RL_tune_res <-
  tune_grid(RL_workflow, resamples = RL_resamples,
            grid = grid_regular(penalty(range = c(-1, 0)), levels = 50))
autoplot(RL_tune_res)
```

```{r}
RL_workflow_final <-
  finalize_workflow(RL_workflow, select_best(RL_tune_res, metric = "rmse"))
results <- fit(RL_workflow_final, data = RL_numeric) %>%
  tidy() %>%
  filter(estimate != 0)
print(results, n = 42)
```

Penalty values being outputted are extremely low. I am wondering if it is 
because the majority of the predictor variables have really low correlation.




